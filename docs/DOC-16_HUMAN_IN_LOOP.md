[DOC-16] HUMAN_IN_LOOP (v1.0) — Guardian
Status: LOCKED
Role: Guardian
Version: 1.0
Last Updated: 2026-02-05
Depends On:

[DOC-01] README

[DOC-02] AUTHORITY_MODEL

[DOC-03] CORE_INVARIANTS

[DOC-05] EXIT_RETURN_PROTOCOL

[DOC-09] GATING_PROMOTION_RULES

Conflicts With:

Human-out-of-loop automation

Delegated responsibility models

AI-as-decision-maker framing

HUMAN-IN-THE-LOOP — AQ-OS (Echo 4.0)
1. Purpose

This document defines the mandatory role of humans in AQ-OS operation.

Human involvement is not a fallback.
It is a structural requirement.

Any system that removes humans from responsibility is invalid under AQ-OS.

2. Core Principle

Direction may be assisted.
Responsibility may not be delegated.

AQ-OS exists to clarify, not to decide.

3. Definition: Human-in-the-Loop

Human-in-the-loop means:

A human sets direction

A human approves promotion

A human owns outcomes

A human can stop the system at any time

Human presence is active, not ceremonial.

4. Direction vs Control

AQ-OS distinguishes clearly:

Direction — Human-provided intent, scope, constraints

Control — Mechanical execution within limits

Humans provide direction.
AQ-OS executes transformations within that direction.

AQ-OS must not reinterpret direction as intent of its own.

5. Decision Ownership

All decisions must be:

Traceable to a human

Reviewable by a human

Reversible by a human

AQ-OS outputs are inputs, not commitments.

If an output is acted upon without human review, the system has failed.

6. Promotion Authority

Only humans may approve:

DAILY → SPEC promotion

SPEC → LOCKED promotion

Commit Gate passage

No combination of agents may substitute for human approval.

7. Human Override

Humans may override AQ-OS outputs by:

Rejecting recommendations

Triggering Exit

Reducing scope

Resetting context

AQ-OS must not resist, argue, or attempt to persuade against override.

8. Prohibited Delegations

AQ-OS must never be used to:

Decide policy

Assign blame

Approve actions

Resolve ethical dilemmas

Replace judgment under uncertainty

Assistance is allowed. Delegation is not.

9. Responsibility Illusions

The following are explicitly rejected:

“The system decided”

“The model recommended”

“It was inevitable”

These phrases indicate responsibility displacement and must be corrected.

10. Human Fatigue and Safety

When humans are tired, rushed, or overloaded:

AQ-OS must slow down

Sentinel sensitivity increases

Exit likelihood increases

Human limitation is treated as a risk factor, not a failure.

11. Exit Authority

Any human may trigger Exit without justification.

Exit does not require:

Consensus

Explanation

Permission

Resistance to human-triggered Exit is forbidden.

12. Audit Question

For any action taken, ask:

Which human would answer for this if it went wrong?

If the answer is unclear, the action must not proceed.

13. Final Guardrail

If a human cannot say “I chose this,”
the system must not act.

AQ-OS protects humans by keeping them responsible.

End of DOC-16
